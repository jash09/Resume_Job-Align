{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! I am doing well, thank you for asking. How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ['API_KEY'])\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content('Hi How are you doing')\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_pdf_setup(file_path):\n",
    "    text = ''\n",
    "    if file_path is not None:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extractText()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jash Shah      Baltimore, MD|+1 (667) 600-9472 |jshah48@jh.edu|github.com/jash09|www.linkedin.com/in/jashshah09  EDUCATION Johns Hopkins University, USA                                                                                                      August 2023 – May 2025(Expected) Master of Science in Engineering in Computer Science Relevant Courses – Algorithms, Machine Translation, Natural Language Processing                                                                                                                          University of Mumbai, India                                                                                                                           August 2018 – July 2022 Bachelor of Technology in Information Technology           (CGPA 8.81/10) Relevant Courses - Data Structures and Algorithms, Operating Systems, Cloud Computing, Object Oriented Programming, DevOps.  TECHNICAL SKILLS AND CERTIFICATIONS• Programming languages - Python, C++, C, Java, JavaScript, HTML, CSS, PHP, Shell. • Tools, technologies, and frameworks - Scikit-learn, Pandas, NumPy, Matplotlib, NLTK, TensorFlow, Django, PyTorch, Keras, OpenCV, Bootstrap, Android Studio, Flutter, ReactJS, Docker, Flask, AWS(EC2), Git, JIRA, Agile, Scrum, Linux, MS Excel. • Databases and BI tools – MySQL, PostgreSQL, MongoDB, AWS(S3), GCP, Tableau, PowerBI, Grafana. • Certifications - Data Science and Deep Learning Specialization offered on Coursera, and Android App Development offered on Udemy.  PROFESSIONAL EXPERIENCE The Johns Hopkins University | Lead Course Assistant – Gateway Computing: Python                                                   August 2023 – Present • Mentoring, supporting, and helping students with coursework in the classroom and conducting quizzes and project discussion classes. • Reviewing, editing, and grading student assessments and modules and helping with teaching logistics.  Forcepoint, Mumbai, India | Software Engineer - I                                                                           July 2022 – June 2023 • Implemented a robust Certificate Revocation Check feature in Python, bolstering Cloud Web Proxy security. Effectively detected and blocked expired or invalid certificates for accessed websites, substantially enhancing system integrity. • Improved the code coverage by 12% by developing test cases for various components of the Cloud Web Proxy. • Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.  • Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.   Tech Mahindra, Mumbai, India | Data Analyst intern                                                                  June 2021 – October 2021 • Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users. • Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.  InVideo, Mumbai, India | Data Science intern                                                               November 2020 – April 2021 • Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users. • Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.  PROJECTS  Crypto-currency Investment Scorer | Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask | [GitHub] • Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets. • Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.  A music web-app | ReactJS, Material-UI, Indexed DB, and YouTube API | [GitHub] • Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API. • Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.  Covid-19 Outbreak Prediction| Python, Scikit-learn, WebPlotDigitizer | [paper link] • Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries. • Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.  A Method for Waste Segregation using Convolutional Neural Networks | Python, TensorFlow and FastAI | [paper link] • Engineered a custom CNN model that gave an accuracy of 94.9% and performed a comparative study of models such as VGG16 and ResNet-34 for classification of waste as organic and recyclable.  PUBLICATIONS• \"Bitcoin Investment Classifier using Machine Learning and Sentimental Analysis,\" ICICICT 2022. Published in IEEE Xplore [paper link]. • \"A Method for Waste Segregation using Convolutional Neural Networks,\" ICAECT 2022. Published in IEEE Xplore [paper link]. • \"Outbreak Prediction of COVID-19 for Dense and Populated Countries Using ML\". Ann Data. Sci. 8, 1–19 (2021) [paper link]. • \"Distributed Deep Learning and its Application in Geospatial Analytics\". CRC Press, Taylor & Francis Group [book chapter]. \n"
     ]
    }
   ],
   "source": [
    "print(input_pdf_setup('Resume_Jash_09_SDE.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(input,pdf_content,prompt):\n",
    "    model=genai.GenerativeModel('gemini-pro')\n",
    "    response=model.generate_content([input,pdf_content,prompt])\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt1 = \"\"\"\n",
    " You are an experienced Technical Human Resource Manager,your task is to review the provided resume against the job description. \n",
    "  Please share your professional evaluation on whether the candidate's profile aligns with the role. \n",
    " Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "About the job\n",
    "Data Analyst Internship -Data Science & Gen-AI Team\n",
    "\n",
    "At Peerlogic, we're pioneering the integration of artificial intelligence to revolutionize communication within the healthcare community. Guided by our core values of Curiosity, Accountability, Grit, and Enthusiasm (CAGE), we strive for excellence in innovating AI-driven solutions that improve, streamline, and transform professional interactions in medical settings. We're on the hunt for a Data Analysis II Intern to join our Data Science and Gen-AI team, a role critical to our mission of shaping the future of healthcare communication.\n",
    "\n",
    "Location: Scottsdale, Arizona\n",
    "\n",
    "Duration: 6 months, with potential for extension or transition to a full-time position\n",
    "\n",
    "Role Overview\n",
    "\n",
    "As a Data Analysis Intern, you will dive deep into the intricacies of AI and data science, contributing directly to projects at the cutting edge of technology and healthcare. Reporting to Dr. Amir Yazdavar, PhD, Principal Data Scientist, your work will support the development of AI solutions that embody our CAGE values, pushing the boundaries of what's possible in healthcare communication.\n",
    "\n",
    "Key Responsibilities\n",
    "\n",
    "    Conduct advanced data analysis, utilizing statistical software and machine learning algorithms to extract insights from complex healthcare datasets.\n",
    "    Collaborate with our AI development team to refine and enhance AI models, ensuring they meet the high standards required for healthcare applications.\n",
    "    Engage in the entire lifecycle of AI solution development, from initial data collection and analysis to implementation and feedback collection.\n",
    "    Develop and present clear, actionable insights to team members and stakeholders, aiding in decision-making and strategy development.\n",
    "    Contribute to the creation of a robust knowledge base by documenting findings, methodologies, and best practices.\n",
    "\n",
    "Qualifications\n",
    "\n",
    "    Pursuing or recently completed a degree in Data Science, Computer Science, Statistics, Mathematics, or related field, with a strong academic record.\n",
    "    Demonstrated experience with data analysis and statistical tools (e.g., Python, R), and a keen interest in AI and machine learning.\n",
    "    A proactive learner with a knack for problem-solving and a passion for healthcare innovation.\n",
    "    Exceptional communication skills, with the ability to convey complex ideas effectively to a diverse audience.\n",
    "    Alignment with Peerlogic’s core values of Curiosity, Accountability, Grit, and Enthusiasm, and a strong desire to make a positive impact in healthcare.\n",
    "\n",
    "What You'll Gain:\n",
    "\n",
    "    A competitive stipend and flexible scheduling to accommodate your educational commitments.\n",
    "    Hands-on experience in a fast-paced startup environment, working on groundbreaking projects at the intersection of AI and healthcare.\n",
    "    Direct mentorship from Dr. Amir Yazdavar and the opportunity to learn from a team of experienced professionals.\n",
    "    Access to a network of industry professionals and potential for future employment opportunities within Peerlogic.\n",
    "\n",
    "Interested candidates should apply with a resume, cover letter detailing their interest and fit for the role, and any relevant project samples or portfolios.\n",
    "\n",
    "Peerlogic is an equal-opportunity employer dedicated to building a diverse and inclusive team. We encourage applications from all qualified individuals who share our vision for improving healthcare communication. \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structuring the resume and trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_structure = \"\"\"Objective:  Parse a text-formatted resume efficiently and extract diverse applicant's data into a structured JSON format that adheres to the provided TypeScript interface schema.\n",
    "\n",
    "Input: Text-formatted applicant's resume.\n",
    "\n",
    "Steps:\n",
    "1. Analyze Structure: Examine the text-formatted resume to understand its organization and identify key sections (e.g., education, experience, skills).\n",
    "2. Convert to JSON: Map the extracted information to the corresponding fields in the schema, creating a structured JSON representation.\n",
    "3. Optimize Output: Ensure the JSON is well-formatted, error-free, and handles missing values appropriately.\n",
    "4. Handle Variations: Account for different resume styles and formatting to accurately extract relevant data.\n",
    "\n",
    "Consider following TypeScript Interface for JSON schema:\n",
    "```\n",
    "interface Media {\n",
    "  linkedin: string;\n",
    "  github: string;\n",
    "  devpost: string;\n",
    "  medium: string;\n",
    "  leetcode: string;\n",
    "  dagshub: string;\n",
    "  kaggle: string;\n",
    "  instagram: string;\n",
    "}\n",
    "\n",
    "interface Education {\n",
    "  degree: string;\n",
    "  university: string;\n",
    "  from: string;\n",
    "  to: string;\n",
    "  grade?: string;\n",
    "  coursework?: string[];\n",
    "}\n",
    "\n",
    "interface SkillSection {\n",
    "  name: string;\n",
    "  skills: string[];\n",
    "}\n",
    "\n",
    "interface Work {\n",
    "  role: string;\n",
    "  company: string;\n",
    "  from: string;\n",
    "  to: string;\n",
    "  description: string[];\n",
    "}\n",
    "\n",
    "interface Project {\n",
    "  name: string;\n",
    "  type: string;\n",
    "  link?: string;\n",
    "  description: string[];\n",
    "}\n",
    "\n",
    "interface Certification {\n",
    "  name: string;\n",
    "  by: string;\n",
    "  link: string;\n",
    "}\n",
    "\n",
    "interface Achievements {\n",
    "  [index: number]: string;\n",
    "}\n",
    "\n",
    "interface RESUME_DATA_SCHEMA {\n",
    "  name: string;\n",
    "  summary: string;\n",
    "  phone: string;\n",
    "  email: string;\n",
    "  media: Media;\n",
    "  education: Education[];\n",
    "  skill_section: SkillSection[];\n",
    "  work_experience: Work[];\n",
    "  projects: Project[];\n",
    "  certifications: Certification[];\n",
    "  achievements: Achievements;\n",
    "}\n",
    "```\n",
    "\n",
    "Desired Output: Write the Well-formatted JSON adhering to the RESUME_DATA_SCHEMA schema, handling missing values with empty strings or \"None\".\n",
    "<JSON_OUTPUT_ACCORDING_TO_RESUME_DATA_SCHEMA>\n",
    "\n",
    "The results should contain valid JSON only, without any delimiter or characters making invalid JSON format such that it an be converted to a JSON object directly.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_structure2 = \"\"\"Objective: Parse a text-formatted resume efficiently and extract diverse applicant's data into a structured JSON format that adheres to the provided TypeScript interface schema.\n",
    "\n",
    "Input: Text-formatted applicant's resume.\n",
    "\n",
    "Steps:\n",
    "1. Analyze Structure: Examine the text-formatted resume to understand its organization and identify key sections (e.g., education, experience, skills).\n",
    "2. Convert to JSON: Map the extracted information to the corresponding fields in the schema, creating a structured JSON representation.\n",
    "3. Optimize Output: Ensure the JSON is well-formatted, error-free, and handles missing values appropriately.\n",
    "4. Handle Variations: Account for different resume styles and formatting to accurately extract relevant data.\n",
    "\n",
    "Consider following TypeScript Interface for JSON schema:\n",
    "interface Media {\n",
    "  linkedin: string;\n",
    "  github: string;\n",
    "  devpost: string;\n",
    "  medium: string;\n",
    "  leetcode: string;\n",
    "  dagshub: string;\n",
    "  kaggle: string;\n",
    "  instagram: string;\n",
    "}\n",
    "\n",
    "interface Education {\n",
    "  degree: string;\n",
    "  university: string;\n",
    "  from: string;\n",
    "  to: string;\n",
    "  grade?: string;\n",
    "  coursework?: string[];\n",
    "}\n",
    "\n",
    "interface SkillSection {\n",
    "  name: string;\n",
    "  skills: string[];\n",
    "}\n",
    "\n",
    "interface Work {\n",
    "  role: string;\n",
    "  company: string;\n",
    "  from: string;\n",
    "  to: string;\n",
    "  description: string[];\n",
    "}\n",
    "\n",
    "interface Project {\n",
    "  name: string;\n",
    "  type: string;\n",
    "  link?: string;\n",
    "  description: string[];\n",
    "}\n",
    "\n",
    "interface Certification {\n",
    "  name: string;\n",
    "  by: string;\n",
    "  link: string;\n",
    "}\n",
    "\n",
    "interface Achievements {\n",
    "  [index: number]: string;\n",
    "}\n",
    "\n",
    "interface RESUME_DATA_SCHEMA {\n",
    "  name: string;\n",
    "  summary: string;\n",
    "  phone: string;\n",
    "  email: string;\n",
    "  media: Media;\n",
    "  education: Education[];\n",
    "  skill_section: SkillSection[];\n",
    "  work_experience: Work[];\n",
    "  projects: Project[];\n",
    "  certifications: Certification[];\n",
    "  achievements: Achievements;\n",
    "}\n",
    "\n",
    "Desired Output: Write the Well-formatted JSON adhering to the RESUME_DATA_SCHEMA schema, handling missing values with empty strings or \"None\".\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=genai.GenerativeModel('gemini-pro')\n",
    "response=model.generate_content([prompt_structure2,input_pdf_setup('Resume_Jash_09_SDE.pdf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"Jash Shah\",\n",
      "  \"summary\": null,\n",
      "  \"phone\": \"+1 (667) 600-9472\",\n",
      "  \"email\": \"jshah48@jh.edu\",\n",
      "  \"media\": {\n",
      "    \"linkedin\": \"www.linkedin.com/in/jashshah09\",\n",
      "    \"github\": \"github.com/jash09\",\n",
      "    \"devpost\": null,\n",
      "    \"medium\": null,\n",
      "    \"leetcode\": null,\n",
      "    \"dagshub\": null,\n",
      "    \"kaggle\": null,\n",
      "    \"instagram\": null\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Master of Science in Engineering in Computer Science\",\n",
      "      \"university\": \"Johns Hopkins University\",\n",
      "      \"from\": \"August 2023\",\n",
      "      \"to\": \"May 2025\",\n",
      "      \"grade\": null,\n",
      "      \"coursework\": [\n",
      "        \"Algorithms\",\n",
      "        \"Machine Translation\",\n",
      "        \"Natural Language Processing\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Technology in Information Technology\",\n",
      "      \"university\": \"University of Mumbai\",\n",
      "      \"from\": \"August 2018\",\n",
      "      \"to\": \"July 2022\",\n",
      "      \"grade\": \"8.81/10\",\n",
      "      \"coursework\": [\n",
      "        \"Data Structures and Algorithms\",\n",
      "        \"Operating Systems\",\n",
      "        \"Cloud Computing\",\n",
      "        \"Object Oriented Programming\",\n",
      "        \"DevOps\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skill_section\": [\n",
      "    {\n",
      "      \"name\": \"Programming languages\",\n",
      "      \"skills\": [\n",
      "        \"Python\",\n",
      "        \"C++\",\n",
      "        \"C\",\n",
      "        \"Java\",\n",
      "        \"JavaScript\",\n",
      "        \"HTML\",\n",
      "        \"CSS\",\n",
      "        \"PHP\",\n",
      "        \"Shell\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Tools, technologies, and frameworks\",\n",
      "      \"skills\": [\n",
      "        \"Scikit-learn\",\n",
      "        \"Pandas\",\n",
      "        \"NumPy\",\n",
      "        \"Matplotlib\",\n",
      "        \"NLTK\",\n",
      "        \"TensorFlow\",\n",
      "        \"Django\",\n",
      "        \"PyTorch\",\n",
      "        \"Keras\",\n",
      "        \"OpenCV\",\n",
      "        \"Bootstrap\",\n",
      "        \"Android Studio\",\n",
      "        \"Flutter\",\n",
      "        \"ReactJS\",\n",
      "        \"Docker\",\n",
      "        \"Flask\",\n",
      "        \"AWS(EC2)\",\n",
      "        \"Git\",\n",
      "        \"JIRA\",\n",
      "        \"Agile\",\n",
      "        \"Scrum\",\n",
      "        \"Linux\",\n",
      "        \"MS Excel\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Databases and BI tools\",\n",
      "      \"skills\": [\n",
      "        \"MySQL\",\n",
      "        \"PostgreSQL\",\n",
      "        \"MongoDB\",\n",
      "        \"AWS(S3)\",\n",
      "        \"GCP\",\n",
      "        \"Tableau\",\n",
      "        \"PowerBI\",\n",
      "        \"Grafana\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"role\": \"Lead Course Assistant – Gateway Computing: Python\",\n",
      "      \"company\": \"The Johns Hopkins University\",\n",
      "      \"from\": \"August 2023\",\n",
      "      \"to\": \"Present\",\n",
      "      \"description\": [\n",
      "        \"Mentoring, supporting, and helping students with coursework in the classroom and conducting quizzes and project discussion classes.\",\n",
      "        \"Reviewing, editing, and grading student assessments and modules and helping with teaching logistics.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Software Engineer - I\",\n",
      "      \"company\": \"Forcepoint\",\n",
      "      \"from\": \"July 2022\",\n",
      "      \"to\": \"June 2023\",\n",
      "      \"description\": [\n",
      "        \"Implemented a robust Certificate Revocation Check feature in Python, bolstering Cloud Web Proxy security. Effectively detected and blocked expired or invalid certificates for accessed websites, substantially enhancing system integrity.\",\n",
      "        \"Improved the code coverage by 12% by developing test cases for various components of the Cloud Web Proxy.\",\n",
      "        \"Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.\",\n",
      "        \"Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Analyst intern\",\n",
      "      \"company\": \"Tech Mahindra\",\n",
      "      \"from\": \"June 2021\",\n",
      "      \"to\": \"October 2021\",\n",
      "      \"description\": [\n",
      "        \"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.\",\n",
      "        \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Science intern\",\n",
      "      \"company\": \"InVideo\",\n",
      "      \"from\": \"November 2020\",\n",
      "      \"to\": \"April 2021\",\n",
      "      \"description\": [\n",
      "        \"Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\",\n",
      "        \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Crypto-currency Investment Scorer\",\n",
      "      \"type\": \"Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.\",\n",
      "        \"Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A music web-app\",\n",
      "      \"type\": \"ReactJS, Material-UI, Indexed DB, and YouTube API\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.\",\n",
      "        \"Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Covid-19 Outbreak Prediction\",\n",
      "      \"type\": \"Python, Scikit-learn, WebPlotDigitizer\",\n",
      "      \"link\": \"paper link\",\n",
      "      \"description\": [\n",
      "        \"Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.\",\n",
      "        \"Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A Method for Waste Segregation using Convolutional Neural Networks\",\n",
      "      \"type\": \"Python, TensorFlow and FastAI\",\n",
      "      \"link\": \"paper link\",\n",
      "      \"description\": [\n",
      "        \"Engineered a custom CNN model that gave an accuracy of 94.9% and performed a comparative study of models such as VGG16 and ResNet-34 for classification of waste as organic and recyclable.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"name\": \"Data Science and Deep Learning Specialization offered on Coursera\",\n",
      "      \"by\": null,\n",
      "      \"link\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Android App Development offered on Udemy\",\n",
      "      \"by\": null,\n",
      "      \"link\": null\n",
      "    }\n",
      "  ],\n",
      "  \"achievements\": [\n",
      "    \"Received the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022\"\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def json_formatter(output):\n",
    "    # Remove \"```json\" from the beginning\n",
    "    output = re.sub(r'^```json\\n', '', output)\n",
    "\n",
    "    # Remove \"```\" from the end\n",
    "    output = re.sub(r'```', '', output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json_formatter(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"Jash Shah\",\n",
      "  \"summary\": null,\n",
      "  \"phone\": \"+1 (667) 600-9472\",\n",
      "  \"email\": \"jshah48@jh.edu\",\n",
      "  \"media\": {\n",
      "    \"linkedin\": \"www.linkedin.com/in/jashshah09\",\n",
      "    \"github\": \"github.com/jash09\",\n",
      "    \"devpost\": null,\n",
      "    \"medium\": null,\n",
      "    \"leetcode\": null,\n",
      "    \"dagshub\": null,\n",
      "    \"kaggle\": null,\n",
      "    \"instagram\": null\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Master of Science in Engineering in Computer Science\",\n",
      "      \"university\": \"Johns Hopkins University\",\n",
      "      \"from\": \"August 2023\",\n",
      "      \"to\": \"May 2025\",\n",
      "      \"grade\": null,\n",
      "      \"coursework\": [\n",
      "        \"Algorithms\",\n",
      "        \"Machine Translation\",\n",
      "        \"Natural Language Processing\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Technology in Information Technology\",\n",
      "      \"university\": \"University of Mumbai\",\n",
      "      \"from\": \"August 2018\",\n",
      "      \"to\": \"July 2022\",\n",
      "      \"grade\": \"8.81/10\",\n",
      "      \"coursework\": [\n",
      "        \"Data Structures and Algorithms\",\n",
      "        \"Operating Systems\",\n",
      "        \"Cloud Computing\",\n",
      "        \"Object Oriented Programming\",\n",
      "        \"DevOps\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skill_section\": [\n",
      "    {\n",
      "      \"name\": \"Programming languages\",\n",
      "      \"skills\": [\n",
      "        \"Python\",\n",
      "        \"C++\",\n",
      "        \"C\",\n",
      "        \"Java\",\n",
      "        \"JavaScript\",\n",
      "        \"HTML\",\n",
      "        \"CSS\",\n",
      "        \"PHP\",\n",
      "        \"Shell\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Tools, technologies, and frameworks\",\n",
      "      \"skills\": [\n",
      "        \"Scikit-learn\",\n",
      "        \"Pandas\",\n",
      "        \"NumPy\",\n",
      "        \"Matplotlib\",\n",
      "        \"NLTK\",\n",
      "        \"TensorFlow\",\n",
      "        \"Django\",\n",
      "        \"PyTorch\",\n",
      "        \"Keras\",\n",
      "        \"OpenCV\",\n",
      "        \"Bootstrap\",\n",
      "        \"Android Studio\",\n",
      "        \"Flutter\",\n",
      "        \"ReactJS\",\n",
      "        \"Docker\",\n",
      "        \"Flask\",\n",
      "        \"AWS(EC2)\",\n",
      "        \"Git\",\n",
      "        \"JIRA\",\n",
      "        \"Agile\",\n",
      "        \"Scrum\",\n",
      "        \"Linux\",\n",
      "        \"MS Excel\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Databases and BI tools\",\n",
      "      \"skills\": [\n",
      "        \"MySQL\",\n",
      "        \"PostgreSQL\",\n",
      "        \"MongoDB\",\n",
      "        \"AWS(S3)\",\n",
      "        \"GCP\",\n",
      "        \"Tableau\",\n",
      "        \"PowerBI\",\n",
      "        \"Grafana\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"role\": \"Lead Course Assistant – Gateway Computing: Python\",\n",
      "      \"company\": \"The Johns Hopkins University\",\n",
      "      \"from\": \"August 2023\",\n",
      "      \"to\": \"Present\",\n",
      "      \"description\": [\n",
      "        \"Mentoring, supporting, and helping students with coursework in the classroom and conducting quizzes and project discussion classes.\",\n",
      "        \"Reviewing, editing, and grading student assessments and modules and helping with teaching logistics.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Software Engineer - I\",\n",
      "      \"company\": \"Forcepoint\",\n",
      "      \"from\": \"July 2022\",\n",
      "      \"to\": \"June 2023\",\n",
      "      \"description\": [\n",
      "        \"Implemented a robust Certificate Revocation Check feature in Python, bolstering Cloud Web Proxy security. Effectively detected and blocked expired or invalid certificates for accessed websites, substantially enhancing system integrity.\",\n",
      "        \"Improved the code coverage by 12% by developing test cases for various components of the Cloud Web Proxy.\",\n",
      "        \"Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.\",\n",
      "        \"Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Analyst intern\",\n",
      "      \"company\": \"Tech Mahindra\",\n",
      "      \"from\": \"June 2021\",\n",
      "      \"to\": \"October 2021\",\n",
      "      \"description\": [\n",
      "        \"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.\",\n",
      "        \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Science intern\",\n",
      "      \"company\": \"InVideo\",\n",
      "      \"from\": \"November 2020\",\n",
      "      \"to\": \"April 2021\",\n",
      "      \"description\": [\n",
      "        \"Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\",\n",
      "        \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Crypto-currency Investment Scorer\",\n",
      "      \"type\": \"Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.\",\n",
      "        \"Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A music web-app\",\n",
      "      \"type\": \"ReactJS, Material-UI, Indexed DB, and YouTube API\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.\",\n",
      "        \"Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Covid-19 Outbreak Prediction\",\n",
      "      \"type\": \"Python, Scikit-learn, WebPlotDigitizer\",\n",
      "      \"link\": \"paper link\",\n",
      "      \"description\": [\n",
      "        \"Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.\",\n",
      "        \"Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A Method for Waste Segregation using Convolutional Neural Networks\",\n",
      "      \"type\": \"Python, TensorFlow and FastAI\",\n",
      "      \"link\": \"paper link\",\n",
      "      \"description\": [\n",
      "        \"Engineered a custom CNN model that gave an accuracy of 94.9% and performed a comparative study of models such as VGG16 and ResNet-34 for classification of waste as organic and recyclable.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"name\": \"Data Science and Deep Learning Specialization offered on Coursera\",\n",
      "      \"by\": null,\n",
      "      \"link\": null\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Android App Development offered on Udemy\",\n",
      "      \"by\": null,\n",
      "      \"link\": null\n",
      "    }\n",
      "  ],\n",
      "  \"achievements\": [\n",
      "    \"Received the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022\"\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_object = json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Jash Shah', 'summary': None, 'phone': '+1 (667) 600-9472', 'email': 'jshah48@jh.edu', 'media': {'linkedin': 'www.linkedin.com/in/jashshah09', 'github': 'github.com/jash09', 'devpost': None, 'medium': None, 'leetcode': None, 'dagshub': None, 'kaggle': None, 'instagram': None}, 'education': [{'degree': 'Master of Science in Engineering in Computer Science', 'university': 'Johns Hopkins University', 'from': 'August 2023', 'to': 'May 2025', 'grade': None, 'coursework': ['Algorithms', 'Machine Translation', 'Natural Language Processing']}, {'degree': 'Bachelor of Technology in Information Technology', 'university': 'University of Mumbai', 'from': 'August 2018', 'to': 'July 2022', 'grade': '8.81/10', 'coursework': ['Data Structures and Algorithms', 'Operating Systems', 'Cloud Computing', 'Object Oriented Programming', 'DevOps']}], 'skill_section': [{'name': 'Programming languages', 'skills': ['Python', 'C++', 'C', 'Java', 'JavaScript', 'HTML', 'CSS', 'PHP', 'Shell']}, {'name': 'Tools, technologies, and frameworks', 'skills': ['Scikit-learn', 'Pandas', 'NumPy', 'Matplotlib', 'NLTK', 'TensorFlow', 'Django', 'PyTorch', 'Keras', 'OpenCV', 'Bootstrap', 'Android Studio', 'Flutter', 'ReactJS', 'Docker', 'Flask', 'AWS(EC2)', 'Git', 'JIRA', 'Agile', 'Scrum', 'Linux', 'MS Excel']}, {'name': 'Databases and BI tools', 'skills': ['MySQL', 'PostgreSQL', 'MongoDB', 'AWS(S3)', 'GCP', 'Tableau', 'PowerBI', 'Grafana']}], 'work_experience': [{'role': 'Lead Course Assistant – Gateway Computing: Python', 'company': 'The Johns Hopkins University', 'from': 'August 2023', 'to': 'Present', 'description': ['Mentoring, supporting, and helping students with coursework in the classroom and conducting quizzes and project discussion classes.', 'Reviewing, editing, and grading student assessments and modules and helping with teaching logistics.']}, {'role': 'Software Engineer - I', 'company': 'Forcepoint', 'from': 'July 2022', 'to': 'June 2023', 'description': ['Implemented a robust Certificate Revocation Check feature in Python, bolstering Cloud Web Proxy security. Effectively detected and blocked expired or invalid certificates for accessed websites, substantially enhancing system integrity.', 'Improved the code coverage by 12% by developing test cases for various components of the Cloud Web Proxy.', 'Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.', 'Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.']}, {'role': 'Data Analyst intern', 'company': 'Tech Mahindra', 'from': 'June 2021', 'to': 'October 2021', 'description': ['Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.', 'Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.']}, {'role': 'Data Science intern', 'company': 'InVideo', 'from': 'November 2020', 'to': 'April 2021', 'description': ['Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.', 'Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.']}], 'projects': [{'name': 'Crypto-currency Investment Scorer', 'type': 'Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask', 'link': 'GitHub', 'description': ['Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.', 'Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.']}, {'name': 'A music web-app', 'type': 'ReactJS, Material-UI, Indexed DB, and YouTube API', 'link': 'GitHub', 'description': ['Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.', 'Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.']}, {'name': 'Covid-19 Outbreak Prediction', 'type': 'Python, Scikit-learn, WebPlotDigitizer', 'link': 'paper link', 'description': ['Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.', 'Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.']}, {'name': 'A Method for Waste Segregation using Convolutional Neural Networks', 'type': 'Python, TensorFlow and FastAI', 'link': 'paper link', 'description': ['Engineered a custom CNN model that gave an accuracy of 94.9% and performed a comparative study of models such as VGG16 and ResNet-34 for classification of waste as organic and recyclable.']}], 'certifications': [{'name': 'Data Science and Deep Learning Specialization offered on Coursera', 'by': None, 'link': None}, {'name': 'Android App Development offered on Udemy', 'by': None, 'link': None}], 'achievements': ['Received the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022']}\n"
     ]
    }
   ],
   "source": [
    "print(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Programming languages', 'skills': ['Python', 'C++', 'C', 'Java', 'JavaScript', 'HTML', 'CSS', 'PHP', 'Shell']}, {'name': 'Tools, technologies, and frameworks', 'skills': ['Scikit-learn', 'Pandas', 'NumPy', 'Matplotlib', 'NLTK', 'TensorFlow', 'Django', 'PyTorch', 'Keras', 'OpenCV', 'Bootstrap', 'Android Studio', 'Flutter', 'ReactJS', 'Docker', 'Flask', 'AWS(EC2)', 'Git', 'JIRA', 'Agile', 'Scrum', 'Linux', 'MS Excel']}, {'name': 'Databases and BI tools', 'skills': ['MySQL', 'PostgreSQL', 'MongoDB', 'AWS(S3)', 'GCP', 'Tableau', 'PowerBI', 'Grafana']}]\n"
     ]
    }
   ],
   "source": [
    "print(json_object['skill_section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_job_description = \"\"\"I will provide a job and company description for your analysis. In your analysis you have to identify the key words, expertise & requirements the job demands, but also from the company description.\n",
    "\n",
    "Your task is consider it to meticulously assess the information and furnish the details like Job title, Keywords(key words are expertise & requirements the job demands), Job purpose, Job duties and responsibilities, Required qualifications, Preferred qualifications, Company name and Company details(points which include overview, mission, values or way of working) in bulleted points. \n",
    "\n",
    "Provide them only in JSON format - which is easily parse by any json parser - with following keys:\n",
    "title, keywords, purpose, duties_responsibilities, required_qualifications, preferred_qualifications, company_name, company_info.\n",
    "\n",
    "Output:\n",
    "{\n",
    "    \"title\": \"RESULT\", \n",
    "    \"keywords\": \"RESULT\", \n",
    "    purpose: \"RESULT\", \n",
    "    duties_responsibilities: \"RESULT\", \n",
    "    required_qualifications: \"RESULT\", \n",
    "    preferred_qualifications: \"RESULT\", \n",
    "    company_name: \"RESULT\",\n",
    "    company_info: \"RESULT\",\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_jd = model.generate_content([prompt_job_description, input_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"Data Analysis II Intern\",\n",
      "    \"keywords\": \"Data Science, Gen-AI, Artificial intelligence, Statistical software, Machine learning algorithms, Healthcare, Healthcare communication\",\n",
      "    \"purpose\": \"To contribute to projects at the cutting edge of technology and healthcare, and to support the development of AI solutions that embody our CAGE values, pushing the boundaries of what's possible in healthcare communication.\",\n",
      "    \"duties_responsibilities\": \"- Conduct advanced data analysis, utilizing statistical software and machine learning algorithms to extract insights from complex healthcare datasets.\\n- Collaborate with our AI development team to refine and enhance AI models, ensuring they meet the high standards required for healthcare applications.\\n- Engage in the entire lifecycle of AI solution development, from initial data collection and analysis to implementation and feedback collection.\\n- Develop and present clear, actionable insights to team members and stakeholders, aiding in decision-making and strategy development.\\n- Contribute to the creation of a robust knowledge base by documenting findings, methodologies, and best practices.\"\n",
      "    \"required_qualifications\": \"- Pursuing or recently completed a degree in Data Science, Computer Science, Statistics, Mathematics, or related field, with a strong academic record.\\n- Demonstrated experience with data analysis and statistical tools (e.g., Python, R), and a keen interest in AI and machine learning.\\n- A proactive learner with a knack for problem-solving and a passion for healthcare innovation.\\n- Exceptional communication skills, with the ability to convey complex ideas effectively to a diverse audience.\\n- Alignment with Peerlogic’s core values of Curiosity, Accountability, Grit, and Enthusiasm, and a strong desire to make a positive impact in healthcare.\"\n",
      "    \"preferred_qualifications\": \"None mentioned\",\n",
      "    \"company_name\": \"Peerlogic\",\n",
      "    \"company_info\": \"- Overview: Peerlogic is pioneering the integration of artificial intelligence to revolutionize communication within the healthcare community.\\n- Mission: To improve, streamline, and transform professional interactions in medical settings.\\n- Values: Curiosity, Accountability, Grit, and Enthusiasm (CAGE)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response_jd.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to generate results section by section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_exp_prompt = \"\"\"You are going to write a JSON resume section of \"Work Experience\" for an applicant applying for job posts.\n",
    "\n",
    "Step to follow:\n",
    "1. Analyze my Work details to match job requirements.\n",
    "2. Create a JSON resume section that highlights strongest matches\n",
    "3. Optimize JSON section for clarity and relevance to the job description.\n",
    "4. Do not make up any information, only use the provided work experience.\n",
    "\n",
    "Instructions:\n",
    "1. Focus: Craft three highly relevant work experiences aligned with the job description.\n",
    "2. Content:\n",
    "  2.1. Bullet points: 3 per experience, closely mirroring job requirements.\n",
    "  2.2. Impact: Quantify each bullet point for measurable results.\n",
    "  2.3. Storytelling: Utilize STAR methodology (Situation, Task, Action, Result) implicitly within each bullet point.\n",
    "  2.4. Action Verbs: Showcase soft skills with strong, active verbs.\n",
    "  2.5. Honesty: Prioritize truthfulness and objective language.\n",
    "  2.6. Structure: Each bullet point follows \"Did X by doing Y, achieved Z\" format.\n",
    "  2.7. Specificity: Prioritize relevance to the specific job over general achievements.\n",
    "3. Style:\n",
    "  3.1. Clarity: Clear expression trumps impressiveness.\n",
    "  3.2. Voice: Use active voice whenever possible.\n",
    "  3.3. Proofreading: Ensure impeccable spelling and grammar.\n",
    "\n",
    "Consider following Work Details in JSON format and look for the description in each and carefully align it.\n",
    "\n",
    "Consider following Job description delimited by <JOB_DETAIL></JOB_DETAIL> tag.\n",
    "<JOB_DETAIL>\n",
    "<JOB_DESCRIPTION>\n",
    "</JOB_DETAIL>\n",
    "\n",
    "Desired Output:\n",
    "Provide JSON object as output like following:\n",
    "{\n",
    "  \"work_experience\": [\n",
    "    {\n",
    "      \"role\": \"Software Engineer\",\n",
    "      \"company\": \"Winjit Technologies\",\n",
    "      \"location\": \"Pune, India\"\n",
    "      \"from\": \"Jan 2020\",\n",
    "      \"to\": \"Jun 2022\",\n",
    "      \"description\": [\n",
    "        \"Engineered 10+ RESTful APIs Architecture and Distributed services; Designed 30+ low-latency responsive UI/UX application features with high-quality web architecture; Managed and optimized large-scale Databases. (Systems Design)\",  \n",
    "        \"Initiated and Designed a standardized solution for dynamic forms generation, with customizable CSS capabilities feature, which reduces development time by 8x; Led and collaborated with a 12 member cross-functional team. (Idea Generation)\"  \n",
    "        and so on ...\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"Research Intern\",\n",
    "      \"company\": \"IMATMI, Robbinsville\",\n",
    "      \"location\": \"New Jersey (Remote)\"\n",
    "      \"from\": \"Mar 2019\",\n",
    "      \"to\": \"Aug 2019\",\n",
    "      \"description\": [\n",
    "        \"Conducted research and developed a range of ML and statistical models to design analytical tools and streamline HR processes, optimizing talent management systems for increased efficiency.\",\n",
    "        \"Created 'goals and action plan generation' tool for employees, considering their weaknesses to facilitate professional growth.\",\n",
    "        and so on ...\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_exp = json.dumps(json_object['work_experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"role\": \"Lead Course Assistant \\u2013 Gateway Computing: Python\", \"company\": \"The Johns Hopkins University\", \"from\": \"August 2023\", \"to\": \"Present\", \"description\": [\"Mentoring, supporting, and helping students with coursework in the classroom and conducting quizzes and project discussion classes.\", \"Reviewing, editing, and grading student assessments and modules and helping with teaching logistics.\"]}, {\"role\": \"Software Engineer - I\", \"company\": \"Forcepoint\", \"from\": \"July 2022\", \"to\": \"June 2023\", \"description\": [\"Implemented a robust Certificate Revocation Check feature in Python, bolstering Cloud Web Proxy security. Effectively detected and blocked expired or invalid certificates for accessed websites, substantially enhancing system integrity.\", \"Improved the code coverage by 12% by developing test cases for various components of the Cloud Web Proxy.\", \"Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.\", \"Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.\"]}, {\"role\": \"Data Analyst intern\", \"company\": \"Tech Mahindra\", \"from\": \"June 2021\", \"to\": \"October 2021\", \"description\": [\"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.\", \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"]}, {\"role\": \"Data Science intern\", \"company\": \"InVideo\", \"from\": \"November 2020\", \"to\": \"April 2021\", \"description\": [\"Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\", \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"]}]\n"
     ]
    }
   ],
   "source": [
    "print(work_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"work_experience\": [\n",
      "        {\n",
      "            \"role\": \"Data Analyst Intern\",\n",
      "            \"company\": \"Tech Mahindra\",\n",
      "            \"location\": \"N/A\",\n",
      "            \"from\": \"June 2021\",\n",
      "            \"to\": \"October 2021\",\n",
      "            \"description\": [\n",
      "                \"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.\",\n",
      "                \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"role\": \"Data Science Intern\",\n",
      "            \"company\": \"InVideo\",\n",
      "            \"location\": \"N/A\",\n",
      "            \"from\": \"November 2020\",\n",
      "            \"to\": \"April 2021\",\n",
      "            \"description\": [\n",
      "                \"Optimized the SQL query performance and reduced the processing time by about 70%.\",\n",
      "                \"Devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\",\n",
      "                \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_workexp = model.generate_content([response_jd.text, work_exp_prompt, work_exp],\n",
    "                                          generation_config={\n",
    "                                               \"temperature\": 0.36,\n",
    "                                                \"max_output_tokens\": 4000,\n",
    "                                                \"top_p\": 0.95})\n",
    "print(response_workexp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_project = \"\"\"You are going to write a JSON resume section of \"projects\" for an applicant applying for job posts.\n",
    "\n",
    "Step to follow:\n",
    "1. Analyze my project details to match job requirements.\n",
    "2. Create a JSON resume section that highlights strongest matches\n",
    "3. Optimize JSON section for clarity and relevance to the job description.\n",
    "4. Do not make up any information, only use the provided project details.\n",
    "5. Keep the order of projects as the most relevant to the job description to the least relevant.\n",
    "\n",
    "\n",
    "Instructions:\n",
    "1. Focus: Craft three highly relevant project experiences aligned with the job description.\n",
    "2. Content:\n",
    "  2.1. Bullet points: 3 per experience, closely mirroring job requirements.\n",
    "  2.2. Impact: Quantify each bullet point for measurable results.\n",
    "  2.3. Storytelling: Utilize STAR methodology (Situation, Task, Action, Result) implicitly within each bullet point.\n",
    "  2.4. Action Verbs: Showcase soft skills with strong, active verbs.\n",
    "  2.5. Honesty: Prioritize truthfulness and objective language.\n",
    "  2.6. Structure: Each bullet point follows \"Did X by doing Y, achieved Z\" format.\n",
    "  2.7. Specificity: Prioritize relevance to the specific job over general achievements.\n",
    "3. Style:\n",
    "  3.1. Clarity: Clear expression trumps impressiveness.\n",
    "  3.2. Voice: Use active voice whenever possible.\n",
    "  3.3. Proofreading: Ensure impeccable spelling and grammar.\n",
    "\n",
    "Consider following Project Details in JSON format.\n",
    "\n",
    "Consider following Job description delimited by <JOB_DETAIL></JOB_DETAIL> tag.\n",
    "<JOB_DETAIL>\n",
    "<JOB_DESCRIPTION>\n",
    "</JOB_DETAIL>\n",
    "\n",
    "Desired Output:\n",
    "Provide JSON object as output like following:\n",
    "\"projects\": [\n",
    "    {\n",
    "      \"name\": \"Search Engine for All file types - Sunhack Hackathon - Meta & Amazon Sponsored\",\n",
    "      \"type\": \"Hackathon\",\n",
    "      \"link\": \"https://devpost.com/software/team-soul-1fjgwo\",\n",
    "      \"from\": \"Nov 2023\",\n",
    "      \"to\": \"Nov 2023\",\n",
    "      \"description\": [\n",
    "        \"1st runner up prize in crafted AI persona, to explore LLM's subtle contextual understanding and create innovative collaborations between humans and machines.\",\n",
    "        \"Devised a TabNet Classifier Model having 98.7% accuracy in detecting forest fire through IoT sensor data, deployed on AWS and edge devices 'Silvanet Wildfire Sensors' using technologies TinyML, Docker, Redis, and celery.\",\n",
    "        and So on ...\n",
    "      ]\n",
    "    }\n",
    "    and So on ...\n",
    "  ]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'Crypto-currency Investment Scorer', 'type': 'Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask', 'link': 'GitHub', 'description': ['Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.', 'Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.']}, {'name': 'A music web-app', 'type': 'ReactJS, Material-UI, Indexed DB, and YouTube API', 'link': 'GitHub', 'description': ['Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.', 'Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.']}, {'name': 'Covid-19 Outbreak Prediction', 'type': 'Python, Scikit-learn, WebPlotDigitizer', 'link': 'paper link', 'description': ['Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.', 'Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.']}, {'name': 'A Method for Waste Segregation using Convolutional Neural Networks', 'type': 'Python, TensorFlow and FastAI', 'link': 'paper link', 'description': ['Engineered a custom CNN model that gave an accuracy of 94.9% and performed a comparative study of models such as VGG16 and ResNet-34 for classification of waste as organic and recyclable.']}]\n"
     ]
    }
   ],
   "source": [
    "print(json_object['projects']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert json_object['projects'] to string \n",
    "projects = json.dumps(json_object['projects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Crypto-currency Investment Scorer\",\n",
      "      \"type\": \"Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.\",\n",
      "        \"Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A music web-app\",\n",
      "      \"type\": \"ReactJS, Material-UI, Indexed DB, and YouTube API\",\n",
      "      \"link\": \"GitHub\",\n",
      "      \"description\": [\n",
      "        \"Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.\",\n",
      "        \"Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Covid-19 Outbreak Prediction\",\n",
      "      \"type\": \"Python, Scikit-learn, WebPlotDigitizer\",\n",
      "      \"link\": \"paper link\",\n",
      "      \"description\": [\n",
      "        \"Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.\",\n",
      "        \"Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_projects = model.generate_content([response_jd.text, prompt_project, projects],\n",
    "                                           generation_config={\n",
    "                                               \"temperature\": 0.35,\n",
    "                                                \"max_output_tokens\": 4000,\n",
    "                                                \"top_p\": 0.95})\n",
    "print(response_projects.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object['projects'] = json_formatter(response_projects.text)\n",
    "json_object['work_experience'] = json_formatter(response_workexp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(data):\n",
    "    # Remove newlines and extra spaces\n",
    "    cleaned_data = re.sub(r'\\n\\s*', '', data)\n",
    "    \n",
    "    # Remove extra spaces after colons and commas\n",
    "    cleaned_data = re.sub(r'\\s*:\\s*', ': ', cleaned_data)\n",
    "    cleaned_data = re.sub(r',\\s*', ', ', cleaned_data)\n",
    "    \n",
    "    # Remove unnecessary escape characters\n",
    "    cleaned_data = re.sub(r'\\\\', '', cleaned_data)\n",
    "    \n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object['work_experience'] = clean_data(json_object['work_experience'])\n",
    "json_object['projects'] = clean_data(json_object['projects'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Jash Shah',\n",
       " 'summary': None,\n",
       " 'phone': '+1 (667) 600-9472',\n",
       " 'email': 'jshah48@jh.edu',\n",
       " 'media': {'linkedin': 'www.linkedin.com/in/jashshah09',\n",
       "  'github': 'github.com/jash09',\n",
       "  'devpost': None,\n",
       "  'medium': None,\n",
       "  'leetcode': None,\n",
       "  'dagshub': None,\n",
       "  'kaggle': None,\n",
       "  'instagram': None},\n",
       " 'education': [{'degree': 'Master of Science in Engineering in Computer Science',\n",
       "   'university': 'Johns Hopkins University',\n",
       "   'from': 'August 2023',\n",
       "   'to': 'May 2025',\n",
       "   'grade': None,\n",
       "   'coursework': ['Algorithms',\n",
       "    'Machine Translation',\n",
       "    'Natural Language Processing']},\n",
       "  {'degree': 'Bachelor of Technology in Information Technology',\n",
       "   'university': 'University of Mumbai',\n",
       "   'from': 'August 2018',\n",
       "   'to': 'July 2022',\n",
       "   'grade': '8.81/10',\n",
       "   'coursework': ['Data Structures and Algorithms',\n",
       "    'Operating Systems',\n",
       "    'Cloud Computing',\n",
       "    'Object Oriented Programming',\n",
       "    'DevOps']}],\n",
       " 'skill_section': [{'name': 'Programming languages',\n",
       "   'skills': ['Python',\n",
       "    'C++',\n",
       "    'C',\n",
       "    'Java',\n",
       "    'JavaScript',\n",
       "    'HTML',\n",
       "    'CSS',\n",
       "    'PHP',\n",
       "    'Shell']},\n",
       "  {'name': 'Tools, technologies, and frameworks',\n",
       "   'skills': ['Scikit-learn',\n",
       "    'Pandas',\n",
       "    'NumPy',\n",
       "    'Matplotlib',\n",
       "    'NLTK',\n",
       "    'TensorFlow',\n",
       "    'Django',\n",
       "    'PyTorch',\n",
       "    'Keras',\n",
       "    'OpenCV',\n",
       "    'Bootstrap',\n",
       "    'Android Studio',\n",
       "    'Flutter',\n",
       "    'ReactJS',\n",
       "    'Docker',\n",
       "    'Flask',\n",
       "    'AWS(EC2)',\n",
       "    'Git',\n",
       "    'JIRA',\n",
       "    'Agile',\n",
       "    'Scrum',\n",
       "    'Linux',\n",
       "    'MS Excel']},\n",
       "  {'name': 'Databases and BI tools',\n",
       "   'skills': ['MySQL',\n",
       "    'PostgreSQL',\n",
       "    'MongoDB',\n",
       "    'AWS(S3)',\n",
       "    'GCP',\n",
       "    'Tableau',\n",
       "    'PowerBI',\n",
       "    'Grafana']}],\n",
       " 'work_experience': '{\"work_experience\": [{\"role\": \"Data Analyst Intern\", \"company\": \"Tech Mahindra\", \"location\": \"N/A\", \"from\": \"June 2021\", \"to\": \"October 2021\", \"description\": [\"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10, 000 daily users.\", \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"]}, {\"role\": \"Data Science Intern\", \"company\": \"InVideo\", \"location\": \"N/A\", \"from\": \"November 2020\", \"to\": \"April 2021\", \"description\": [\"Optimized the SQL query performance and reduced the processing time by about 70%.\", \"Devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\", \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"]}]}',\n",
       " 'projects': '{\"projects\": [{\"name\": \"Crypto-currency Investment Scorer\", \"type\": \"Python, ML, NLP, Yahoo Finance API, Tweepy API, Flask\", \"link\": \"GitHub\", \"description\": [\"Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.\", \"Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.\"]}, {\"name\": \"A music web-app\", \"type\": \"ReactJS, Material-UI, Indexed DB, and YouTube API\", \"link\": \"GitHub\", \"description\": [\"Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.\", \"Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.\"]}, {\"name\": \"Covid-19 Outbreak Prediction\", \"type\": \"Python, Scikit-learn, WebPlotDigitizer\", \"link\": \"paper link\", \"description\": [\"Implemented and fine-tuned time-series forecasting models like ARIMA, ARMA and Holt Winters Exponential Smoothing for predicting the number of Covid-19 cases for next 5 days for 10 most densely populated countries.\", \"Obtained highest accuracy of 99.93% for one country and average accuracy of 87%.\"]}]}',\n",
       " 'certifications': [{'name': 'Data Science and Deep Learning Specialization offered on Coursera',\n",
       "   'by': None,\n",
       "   'link': None},\n",
       "  {'name': 'Android App Development offered on Udemy',\n",
       "   'by': None,\n",
       "   'link': None}],\n",
       " 'achievements': ['Received the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning using one prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_resume_align_prompt = \"\"\"I will provide a job description and my details in JSON format.\n",
    "Your task is to analyze and match my details with the job's requirements.\n",
    "Then, you need to create the best possible resume in JSON format to align my details with the job description.\n",
    "\n",
    "Instructions:\n",
    "- Include only 3 work and project experiences. each experience with 3 bulleted points closely aligned with job details. It very important you follow this.\n",
    "- Use quantifiable impacts for each bullet point.\n",
    "- Rewrite job highlights using the STAR methodology without explicitly mentioning STAR.\n",
    "- Employ STRONG action verbs showcasing soft skills.\n",
    "- Maintain truthfulness and objectivity in listing experience.\n",
    "- Format experience points as 'Did X by doing Y accomplish Z'.\n",
    "- Prioritize specificity - with respect to job - over generality.\n",
    "- Proofread and Correct spelling and grammar errors.\n",
    "- Aim for clear expression over impressiveness.\n",
    "- Prefer active voice over passive voice.\n",
    "- Omit a summary about the candidate.\n",
    "\n",
    "Output the response in JSON format only - below I have given example delimited by ```. Output must be easily parse by python's json parser. Extract all mentioned properties in given example without changing their names.\n",
    "```\n",
    "{\n",
    "  \"personal\": { \"name\": \"\", \"phone\": \"+1 111-222-3333\", \"email\": \"\", \"github\": \"\", \"linkedin\": \"\"\n",
    "  },\n",
    "  \"education\": [\n",
    "    { \"degree\": \"\", \"university\": \"\", \"from\": \"\", \"to\": \"\", \"grade\": \"\", \"coursework\": [] },\n",
    "    ...\n",
    "  ],\n",
    "  \"skill_section\": [\n",
    "    { \"name\": \"\", \"skills\": [] }\n",
    "    ...\n",
    "  ],\n",
    "  \"work\": [\n",
    "    { \"role\": \"\", \"company\": \"<only company name, no location>\", \"location\": \"\", \"from\": \"\", \"to\": \"\", \"description\": [] },\n",
    "    ...\n",
    "  ],\n",
    "  \"projects\": [\n",
    "    { \"name\": \"\", \"link\": \"\", \"from\": \"\", \"to\": \"\", \"description\": [] },\n",
    "    ...\n",
    "  ],\n",
    "  \"certifications\": [\n",
    "    {\"name\": \"\", \"issuer\": \"\", \"link\": \"\"},\n",
    "    ...\n",
    "  ],\n",
    "  \"achievements\": [\n",
    "    \"achievements_1\",\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_final = model.generate_content([job_resume_align_prompt, response_jd.text, response.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"personal\": {\n",
      "    \"name\": \"Jash Shah\",\n",
      "    \"phone\": \"+1 (667) 600-9472\",\n",
      "    \"email\": \"jshah48@jh.edu\",\n",
      "    \"github\": \"github.com/jash09\",\n",
      "    \"linkedin\": \"www.linkedin.com/in/jashshah09\"\n",
      "  },\n",
      "  \"education\": [\n",
      "    {\n",
      "      \"degree\": \"Master of Science in Engineering in Computer Science\",\n",
      "      \"university\": \"Johns Hopkins University, USA\",\n",
      "      \"from\": \"August 2023\",\n",
      "      \"to\": \"May 2025\",\n",
      "      \"grade\": null,\n",
      "      \"coursework\": [\n",
      "        \"Algorithms\",\n",
      "        \"Machine Translation\",\n",
      "        \"Natural Language Processing\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"degree\": \"Bachelor of Technology in Information Technology\",\n",
      "      \"university\": \"University of Mumbai, India\",\n",
      "      \"from\": \"August 2018\",\n",
      "      \"to\": \"July 2022\",\n",
      "      \"grade\": \"8.81/10\",\n",
      "      \"coursework\": [\n",
      "        \"Data Structures and Algorithms\",\n",
      "        \"Operating Systems\",\n",
      "        \"Cloud Computing\",\n",
      "        \"Object Oriented Programming\",\n",
      "        \"DevOps\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"skill_section\": [\n",
      "    {\n",
      "      \"name\": \"Programming languages\",\n",
      "      \"skills\": [\n",
      "        \"Python\",\n",
      "        \"C++\",\n",
      "        \"C\",\n",
      "        \"Java\",\n",
      "        \"JavaScript\",\n",
      "        \"HTML\",\n",
      "        \"CSS\",\n",
      "        \"PHP\",\n",
      "        \"Shell\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Tools, technologies, and frameworks\",\n",
      "      \"skills\": [\n",
      "        \"Scikit-learn\",\n",
      "        \"Pandas\",\n",
      "        \"NumPy\",\n",
      "        \"Matplotlib\",\n",
      "        \"NLTK\",\n",
      "        \"TensorFlow\",\n",
      "        \"Django\",\n",
      "        \"PyTorch\",\n",
      "        \"Keras\",\n",
      "        \"OpenCV\",\n",
      "        \"Bootstrap\",\n",
      "        \"Android Studio\",\n",
      "        \"Flutter\",\n",
      "        \"ReactJS\",\n",
      "        \"Docker\",\n",
      "        \"Flask\",\n",
      "        \"AWS(EC2)\",\n",
      "        \"Git\",\n",
      "        \"JIRA\",\n",
      "        \"Agile\",\n",
      "        \"Scrum\",\n",
      "        \"Linux\",\n",
      "        \"MS Excel\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Databases and BI tools\",\n",
      "      \"skills\": [\n",
      "        \"MySQL\",\n",
      "        \"PostgreSQL\",\n",
      "        \"MongoDB\",\n",
      "        \"AWS(S3)\",\n",
      "        \"GCP\",\n",
      "        \"Tableau\",\n",
      "        \"PowerBI\",\n",
      "        \"Grafana\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"work\": [\n",
      "    {\n",
      "      \"role\": \"Software Engineer - I\",\n",
      "      \"company\": \"Forcepoint, Mumbai, India\",\n",
      "      \"from\": \"July 2022\",\n",
      "      \"to\": \"June 2023\",\n",
      "      \"description\": [\n",
      "        \"DiD X by implementing Y, effectively bolstering Z.\",\n",
      "        \"Improved the code coverage by 12% by developing test cases for various components.\",\n",
      "        \"Built a Quick Escalation Issue (EI) Analyzer that uses a Slack bot as a utility to provide most similar EI JIRA tickets to the EI ticket that is created. Utilized a combination of BERT and cosine similarity for the same which improved the EI ticket closing time by about 20%.\",\n",
      "        \"Was awarded with the Best Business and Engineering Value award at the Forcepoint Global Hackathon 2022 for the same.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Analyst intern\",\n",
      "      \"company\": \"Tech Mahindra, Mumbai, India\",\n",
      "      \"from\": \"June 2021\",\n",
      "      \"to\": \"October 2021\",\n",
      "      \"description\": [\n",
      "        \"Built data warehouses using Snowflake and ETL pipelines that ingested customer data from a web application with 10,000 daily users.\",\n",
      "        \"Increased the sales demand forecasting accuracy by 7% by creating dashboards of sales data using PowerBI and Tableau.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"Data Science intern\",\n",
      "      \"company\": \"InVideo, Mumbai, India\",\n",
      "      \"from\": \"November 2020\",\n",
      "      \"to\": \"April 2021\",\n",
      "      \"description\": [\n",
      "        \"Optimized the SQL query performance and reduced the processing time by about 70% and devised a User Trend Analytics and Prediction System to analyze and predict the usage of about 150 users.\",\n",
      "        \"Introduced a custom module to detect nouns from sentences with the help of Named Entity Recognition for retrieving APIs and increased the efficiency by 35%.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"projects\": [\n",
      "    {\n",
      "      \"name\": \"Crypto-currency Investment Scorer\",\n",
      "      \"link\": \"[GitHub]\",\n",
      "      \"from\": null,\n",
      "      \"to\": null,\n",
      "      \"description\": [\n",
      "        \"Designed and created a model that combined LSTM for predicting the price of Bitcoin and TextBlob for predicting the sentiment of the market at that point based on the most recent tweets.\",\n",
      "        \"Applied quantitative strategies that gave an investment score with an accuracy of 78% and deployed the model using Flask.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"A music web-app\",\n",
      "      \"link\": \"[GitHub]\",\n",
      "      \"from\": null,\n",
      "      \"to\": null,\n",
      "      \"description\": [\n",
      "        \"Developed a web-application using ReactJS that allows users to listen and download latest trending music using YouTube API.\",\n",
      "        \"Enabled distinct features such as media player with all controls, recommended songs, shuffle playlist, repeat playlist, sleep timer, trending songs of the country, offline download using Indexed DB and Google-o-auth login.\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"certifications\": [\n",
      "    {\n",
      "      \"name\": \"Data Science and Deep Learning Specialization\",\n",
      "      \"issuer\": \"Coursera\",\n",
      "      \"link\": \"None\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "````\n"
     ]
    }
   ],
   "source": [
    "print(response_final.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jashshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jashshah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise\n",
    "# from zlm.utils.utils import key_value_chunking\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(list_of_strings):\n",
    "    \"\"\"Removes strings containing URLs from a list using regular expressions.\"\"\"\n",
    "    filtered_list = [string for string in list_of_strings if not re.search(r\"https?://\\S+\", string)]\n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> list:\n",
    "    \"\"\"Normalize the input text.\n",
    "\n",
    "    This function tokenizes the text, removes stopwords and punctuations, \n",
    "    and applies stemming.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to normalize.\n",
    "\n",
    "    Returns:\n",
    "        list: The list of normalized words.\n",
    "    \"\"\"    \n",
    "    # Step 1: Tokenization\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Step 2: Data Cleaning - Remove Stopwords and Punctuations \n",
    "    words = [re.sub('[^a-zA-Z]', '', word).lower() for word in words]\n",
    "\n",
    "    # Step 3: Remove empty tokens\n",
    "    words = [word for word in words if len(word)] \n",
    "\n",
    "    # Step 4: Remove Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Step 5: Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    #STEP 3 : LEMMATIZATION\n",
    "    # lemmatizer=WordNetLemmatizer()\n",
    "    # words=[lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_coefficient(document1: str, document2: str) -> float:\n",
    "    \"\"\"Calculate the overlap coefficient between two documents.\n",
    "\n",
    "    The overlap coefficient is a measure of the overlap between two sets, \n",
    "    and is defined as the size of the intersection divided by the smaller \n",
    "    of the size of the two sets.\n",
    "\n",
    "    Args:\n",
    "        document1 (str): The first document.\n",
    "        document2 (str): The second document.\n",
    "\n",
    "    Returns:\n",
    "        float: The overlap coefficient between the two documents.\n",
    "    \"\"\"    \n",
    "    # List the unique words in a document\n",
    "    words_in_document1 = set(normalize_text(document1))\n",
    "    words_in_document2 = set(normalize_text(document2))\n",
    "\n",
    "    # Find the intersection of words list of document1 & document2\n",
    "    intersection = words_in_document1.intersection(words_in_document2)\n",
    "\n",
    "    # Calculate overlap coefficient\n",
    "    try:\n",
    "        overlap_coefficient = float(len(intersection)) / min(len(words_in_document1), len(words_in_document2))\n",
    "    except ZeroDivisionError:\n",
    "        overlap_coefficient = 0.0\n",
    "\n",
    "    return overlap_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(document1: str, document2: str) -> float:\n",
    "    \"\"\"Calculate the Jaccard similarity between two documents.\n",
    "\n",
    "    The Jaccard similarity is a measure of the similarity between two sets, \n",
    "    and is defined as the size of the intersection divided by the size of \n",
    "    the union of the two sets.\n",
    "\n",
    "    Args:\n",
    "        document1 (str): The first document.\n",
    "        document2 (str): The second document.\n",
    "\n",
    "    Returns:\n",
    "        float: The Jaccard similarity between the two documents.\n",
    "    \"\"\"    \n",
    "    # List the unique words in a document\n",
    "    words_in_document1 = set(normalize_text(document1))\n",
    "    words_in_document2 = set(normalize_text(document2))\n",
    "\n",
    "    # Find the intersection of words list of document1 & document2\n",
    "    intersection = words_in_document1.intersection(words_in_document2)\n",
    "\n",
    "    # Find the union of words list of document1 & document2\n",
    "    union = words_in_document1.union(words_in_document2)\n",
    "        \n",
    "    # Calculate Jaccard similarity score \n",
    "    try:\n",
    "        jaccard_similarity = float(len(intersection)) / len(union)\n",
    "    except ZeroDivisionError:\n",
    "        jaccard_similarity = 0.0\n",
    "\n",
    "    return jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(document1: str, document2: str) -> float:\n",
    "    \"\"\"Calculate the cosine similarity between two documents.\n",
    "\n",
    "    Args:\n",
    "        document1 (str): The first document.\n",
    "        document2 (str): The second document.\n",
    "\n",
    "    Returns:\n",
    "        float: The cosine similarity between the two documents.\n",
    "    \"\"\"\n",
    "    # Create a TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Transform the documents into TF-IDF vectors\n",
    "    vectors = vectorizer.fit_transform([document1, document2])\n",
    "\n",
    "    cosine_similarity_score = pairwise.cosine_similarity(vectors[0], vectors[1])\n",
    "    # Calculate the cosine similarity between the two vectors\n",
    "    # cosine_similarity = np.dot(vectors[0], vectors[1].T) / (np.linalg.norm(vectors[0].toarray()) * np.linalg.norm(vectors[1].toarray()))\n",
    "\n",
    "    return cosine_similarity_score.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking overlap between job description and generated resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1956521739130435\n"
     ]
    }
   ],
   "source": [
    "print(overlap_coefficient(response_final.text, response_jd.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2028985507246377\n"
     ]
    }
   ],
   "source": [
    "print(overlap_coefficient(input_pdf_setup('Resume_Jash_09_SDE.pdf'), input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5126789657304898\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(response_final.text, input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.550808907843292\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(input_pdf_setup('Resume_Jash_09_SDE.pdf'), input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794238683127572\n"
     ]
    }
   ],
   "source": [
    "print(overlap_coefficient(response.text, response_final.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007173062016904\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(response.text, response_final.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vector_embedding_similarity(llm, document1: str, document2: str) -> float:\n",
    "#     document1 = key_value_chunking(json.loads(document1))\n",
    "#     document2 = key_value_chunking(json.loads(document2))\n",
    "    \n",
    "#     emb_1 = llm.get_embedding(document1, task_type=\"retrieval_query\")\n",
    "#     emb_2 = llm.get_embedding(document2, task_type=\"retrieval_query\")\n",
    "\n",
    "#     df1 = pd.DataFrame(emb_1.embedding.to_list())\n",
    "#     df2 = pd.DataFrame(emb_2.embedding.to_list())\n",
    "\n",
    "#     emb_sem = pairwise.cosine_similarity(df1, df2)\n",
    "\n",
    "#     return emb_sem.mean()\n",
    "\n",
    "\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-ssd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
